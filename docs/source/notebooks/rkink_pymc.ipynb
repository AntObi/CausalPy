{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression kink analysis with `pymc` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import causalpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression kink designs should be analysed by a piecewise continuous function. That is:\n",
    "* We want a function which can capture the data to the left and to the right of the kink point.\n",
    "* We want a piecewise function with one breakpoint or kink point\n",
    "* The function should be continuous at the kink point\n",
    "\n",
    "An example of such a function would be a piecewise continuous polynomial:\n",
    "\n",
    "$$\n",
    "\\mu = \\beta_0 + \\beta_1 \\cdot x + \\beta_2 \\cdot x^2 + \\beta_3 \\cdot (x-k) + \\beta_4 \\cdot (x-k)^2\n",
    "$$\n",
    "\n",
    "We can visualise what these functions look like by plotting a number of them with randomly chosen $\\beta$ coefficients, but all with a kink point at $x=0.5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, beta, kink):\n",
    "    return (\n",
    "        beta[0]\n",
    "        + beta[1] * x\n",
    "        + beta[2] * x**2\n",
    "        + beta[3] * (x - kink) * (x >= kink)\n",
    "        + beta[4] * (x - kink) ** 2 * (x >= kink)\n",
    "    )\n",
    "\n",
    "\n",
    "def gradient_change(beta, kink, epsilon=0.01):\n",
    "    gradient_left = (f(kink, beta, kink) - f(kink - epsilon, beta, kink)) / epsilon\n",
    "    gradient_right = (f(kink + epsilon, beta, kink) - f(kink, beta, kink)) / epsilon\n",
    "    gradient_change = gradient_right - gradient_left\n",
    "    return gradient_change\n",
    "\n",
    "\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "kink = 0.5\n",
    "sigma = 0.05\n",
    "cols = 5\n",
    "\n",
    "fig, ax = plt.subplots(2, cols, sharex=True, sharey=True, figsize=(15, 5))\n",
    "\n",
    "for col in range(cols):\n",
    "    beta = rng.random(5)\n",
    "    ax[0, col].plot(x, f(x, beta, kink), lw=3)\n",
    "    ax[1, col].plot(x, np.gradient(f(x, beta, kink), x), lw=3)\n",
    "    ax[0, col].set(title=f\"Random  {col+1}\")\n",
    "    ax[1, col].set(xlabel=\"x\")\n",
    "\n",
    "ax[0, 0].set(ylabel=\"$y = f(x)$\")\n",
    "ax[1, 0].set(ylabel=r\"$\\frac{dy}{dx}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of regression kink analysis is to fit a suitable function to data and to estimate whether there is a change in the gradient of the function at the kink point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will generate a number of datasets and run through how to conduct the regression kink analysis. We will use a function to generate simulated datasets with the properties we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(beta, kink, sigma=0.05, N=50):\n",
    "    if beta is None:\n",
    "        beta = rng.random(5)\n",
    "    x = rng.uniform(-1, 1, N)\n",
    "    y = f(x, beta, kink) + rng.normal(0, sigma, N)\n",
    "    df = pd.DataFrame({\"x\": x, \"y\": y, \"treated\": x >= kink})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - continuous piecewise linear function\n",
    "In this example we'll stick to a simple continuous piecewise function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kink = 0.5\n",
    "beta = [0, -1, 0, 2, 0]\n",
    "df = generate_data(beta, kink, sigma=sigma)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"x\"], df[\"y\"], alpha=0.5)\n",
    "ax.axvline(kink, color=\"red\", linestyle=\"--\")\n",
    "ax.set(title=f\"Change in gradient at kink point: {gradient_change(beta, kink):.2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the regular `cp.pymc_models.LinearRegression` model and enforce the continuous piecewise nature by cleverly specifying a design matrix via the `formula` input.\n",
    "\n",
    "In this example, setting the formula to `\"y ~ 1 + x + I((x-0.5)*treated)\"` (where the 0.5 is the kink point) equates to the following model:\n",
    "\n",
    "$$\n",
    "\\mu = \\beta_0 + \\beta_1 \\cdot x + \\beta_3 \\cdot (x-k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = cp.pymc_experiments.RegressionKink(\n",
    "    df,\n",
    "    formula=f\"y ~ 1 + x + I((x-{kink})*treated)\",\n",
    "    model=cp.pymc_models.LinearRegression(sample_kwargs={\"random_seed\": seed}),\n",
    "    kink_point=kink,\n",
    "    epsilon=0.1,\n",
    ")\n",
    "\n",
    "fig, ax = result1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to plot the posterior distribution of the inferred gradient change, you can do it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_posterior(result1.gradient_change, ref_val=gradient_change(beta, kink))\n",
    "ax.set(title=\"Gradient change\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the correct gradient change is 2, and that we have correctly recovered it as the posterior distribution is centred around 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - continuous piecewise polynomial function\n",
    "\n",
    "Now we'll introduce some nonlinearity into the mix.\n",
    "\n",
    "In this example, we're going to have a 2nd order polynomial on either side of the kink point. So the model can be defined as:\n",
    "\n",
    "$$\n",
    "\\mu = \\beta_0 + \\beta_1 \\cdot x + \\beta_2 \\cdot x^2 + \\beta_3 \\cdot (x-k) + \\beta_4 \\cdot (x-k)^2\n",
    "$$\n",
    "\n",
    "While it's a bit verbose, we can implement this in a [patsy](https://patsy.readthedocs.io/en/latest/index.html) formula as so:\n",
    "\n",
    "> `\"y ~ 1 + x + np.power(x,2) + I((x-0.5)*treated) + I(np.power((x-0.5), 2)*treated)\"` \n",
    "\n",
    "where the 0.5 is the kink point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kink = 0.5\n",
    "beta = [0, 0, 1, -1, -5]\n",
    "df = generate_data(beta, kink, N=200, sigma=sigma)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"x\"], df[\"y\"], alpha=0.5)\n",
    "ax.axvline(kink, color=\"red\", linestyle=\"--\")\n",
    "ax.set(title=f\"Change in gradient at kink point: {gradient_change(beta, kink):.2f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = f\"y ~ 1 + x + np.power(x,2) + I((x-{kink})*treated) + I(np.power(x-{kink}, 2)*treated)\"\n",
    "\n",
    "result2 = cp.pymc_experiments.RegressionKink(\n",
    "    df,\n",
    "    formula=formula,\n",
    "    model=cp.pymc_models.LinearRegression(\n",
    "        sample_kwargs={\"random_seed\": seed, \"tune\": 5_000, \"target_accept\": 0.95}\n",
    "    ),\n",
    "    kink_point=kink,\n",
    "    epsilon=0.01,\n",
    ")\n",
    "\n",
    "fig, ax = result2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the posterior distribution of the parameters and see how they match up with the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beta, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(result2.idata, var_names=\"~mu\", figsize=(10, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_posterior(result2.gradient_change, ref_val=gradient_change(beta, kink))\n",
    "ax.set(title=\"Gradient change\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 - basis spline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = cp.pymc_experiments.RegressionKink(\n",
    "    df,\n",
    "    formula=f\"y ~ 1 + bs(x, df=3) + bs(I(x-{kink})*treated, df=3)\",\n",
    "    model=cp.pymc_models.LinearRegression(sample_kwargs={\"random_seed\": seed}),\n",
    "    kink_point=kink,\n",
    ")\n",
    "\n",
    "result3.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_posterior(result3.gradient_change, ref_val=gradient_change(beta, kink))\n",
    "ax.set(title=\"Gradient change\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CausalPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46d31859cc45aa26a1223a391e7cf3023d69984b498bed11e66c690302b7e251"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
